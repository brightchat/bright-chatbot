from __future__ import annotations
import re
from typing import Any, Dict, Tuple, Union

from openai_mobile.services._base_handler import OpenAITaskBaseHandler
from openai_mobile import models


class ChatReplyHandler(OpenAITaskBaseHandler):
    """
    Handler for the task of generating a reply to a user message.
    """

    def reply(
        self,
        prompt: models.MessagePrompt,
        user_session: models.UserSession,
    ) -> models.HandlerOutput:
        """
        Generates a response to a message prompt and sends it to the user via the
        communication provider.
        """
        self.logger.info(f"Generating answer from user prompt: '{prompt}'")
        txt_answer = self._generate_answer(prompt)
        self.logger.info(f"Model generated the answer: '{txt_answer}'")
        parsed_answer = self._parse_model_answer(txt_answer)
        response = models.MessageResponse(
            body=parsed_answer["response_body"], to_user=prompt.from_user
        )
        self.client.send_response(response)
        self.client.save_response(response, user_session)
        output = models.HandlerOutput(
            message_prompt=prompt,
            message_response=response,
            context={
                "raw": txt_answer,
            },
            requested_features={
                "generate_image": parsed_answer["image"],
            },
        )
        self.logger.info(f"Sent chat reply with output: '{output}'")
        return output

    def _generate_answer(
        self,
        prompt: models.MessagePrompt,
    ) -> str:
        """
        Generates a response to a message prompt using the OpenAI API.
        """
        chat_history = [
            *self.client.chat_history.to_chat_representation(),
            prompt.to_chat_repr(),
        ]
        self.logger.debug(f"Generating an answer from chat: '{chat_history}'")
        completion = self.openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=chat_history,
            user=prompt.from_user.hashed_user_id,
            max_tokens=420,
        )
        answer_txt = completion.choices[0].message.content.strip()
        return answer_txt

    def _parse_model_answer(self, answer: str) -> Dict[str, Any]:
        """
        Parses the answer generated by the OpenAI API
        """
        image, answer = self.get_image_prompt_from_answer(answer)
        replies = re.findall(r"Reply\((.*?)\)", answer)
        reply = replies[0] if replies else None
        return {
            "response_body": reply if reply else answer,
            "image": image,
        }

    def get_image_prompt_from_answer(self, answer: str) -> Tuple[Union[str, None], str]:
        """
        Returns the image prompt from the answer generated by the OpenAI API
        and the answer without the image prompt.
        """
        patterns = [
            r"Image\([\"']?(.*?)[\"']?\)",
            r"Image:\s*\(?[\"']?(.*)[\"']?\)?",
            r".*?generating.*?image.*?[\r\n]{2,}(.*)",
        ]
        for pattern in patterns:
            matches = re.findall(pattern, answer, flags=re.IGNORECASE)
            if matches:
                return matches[0], re.sub(pattern, "", answer, flags=re.IGNORECASE)
        return None, answer
